{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.1 (SDL 2.28.2, Python 3.9.17)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pymoo.core.problem import Problem\n",
    "from utils import simulation, verify_solution, init_env, run_pymoo_algorithm, initialise_script\n",
    "from fitness_functions import original_fitness, individual_gain\n",
    "\n",
    "\n",
    "from evoman.environment import Environment\n",
    "from pymoo.algorithms.soo.nonconvex.pattern import PatternSearch\n",
    "from pymoo.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class objectives(Problem):\n",
    "    enemies: list[int]\n",
    "    env: Environment\n",
    "\n",
    "    def __init__(self, env: Environment, n_genes: int, enemies: list[int], n_objectives):\n",
    "        self.env = env\n",
    "        self.enemies = enemies\n",
    "        super().__init__(n_var=n_genes, n_obj=n_objectives, xl=-1, xu=1, type_var=float)\n",
    "\n",
    "    def _evaluate(self, x: list[np.array], out, *args, **kwargs):\n",
    "        \"\"\"Evaluate the fitness of each individual in the population\n",
    "        We can turn on elementwise_evaluation to evaluate each individual in the population separately\n",
    "        https://pymoo.org/problems/parallelization.html#Custom-Parallelization\n",
    "\n",
    "        x - list of individuals in the population\n",
    "        out - dictionary with the fitness outputs\n",
    "\n",
    "        # when we have multiple enemies we need to average the fitness somehow\n",
    "        # Ideas: mean of the fitness will show how agent performs with both enemies\n",
    "        #        max will show how agent performs with the worst enemy (this does not reflect the performance with\n",
    "        #        another enemy)\n",
    "        #        weighted average is another option, but then we have another problem of how to weight the enemies\n",
    "        \"\"\"\n",
    "        if POP_SIZE != len(x):\n",
    "            print(f\"WARNING: POP_SIZE != len(x) in evaluation step (this happens sometimes do not see why)\\n\"\n",
    "                  f\"pop size: {POP_SIZE}; len x:{len(x)}\")\n",
    "        # Initialize\n",
    "        dict_enemies = {}\n",
    "        # Get fitness for each enemy\n",
    "        for enemy in self.enemies:\n",
    "            self.env.update_parameter('enemies', [enemy])\n",
    "\n",
    "            dict_enemies[enemy] = []\n",
    "            for individual_id in range(len(x)):\n",
    "                dict_enemies[enemy].append(\n",
    "                    simulation(self.env, x[individual_id], inverted_fitness=True, fitness_function=individual_gain))\n",
    "\n",
    "        # Return fitness outputs for enemies\n",
    "        objectives_fitness = {\n",
    "            \"objective_hard\": [np.mean([dict_enemies[enemy_id][ind_id] for enemy_id in [1, 6]]) for ind_id in\n",
    "                               range(len(x))],\n",
    "            \"objective_medium\": [np.mean([dict_enemies[enemy_id][ind_id] for enemy_id in [2, 5, 8]]) for ind_id in\n",
    "                                 range(len(x))],\n",
    "            \"objective_easy\": [np.mean([dict_enemies[enemy_id][ind_id] for enemy_id in [3, 4, 7]]) for ind_id in\n",
    "                               range(len(x))],\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions = []\n",
    "for file in os.listdir('solutions_beats_5_enemies'):\n",
    "    if file.startswith('pymoo'):\n",
    "        new_solution = []\n",
    "        with open(f'solutions_beats_5_enemies/{file}') as f:\n",
    "            solutions.append(f.read().splitlines())\n",
    "            \n",
    "solutions = np.array(solutions, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENEMIES = [2, 3, 6]\n",
    "env, n_genes = init_env('local_search_test', ENEMIES, 10)\n",
    "problem = objectives(\n",
    "        env=env,\n",
    "        n_genes=n_genes,\n",
    "        enemies=ENEMIES,\n",
    "        n_objectives=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\beuze\\anaconda3\\envs\\ec110\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3534: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "POP_SIZE = solutions.shape[0]\n",
    "algorithm = PatternSearch(n_sample_points=POP_SIZE)\n",
    "res = minimize(\n",
    "    problem,\n",
    "    algorithm,\n",
    "    seed=1)\n",
    "\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ec110",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
